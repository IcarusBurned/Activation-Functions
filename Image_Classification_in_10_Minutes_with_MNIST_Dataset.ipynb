{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification in 10 Minutes with MNIST Dataset ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IcarusBurned/Activation-Functions/blob/master/Image_Classification_in_10_Minutes_with_MNIST_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hee6VjKqIJ3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import csv\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot\n",
        "#from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugnATZNhLgOR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "UseMnist = True\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKtwMvvsj_zp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load my data set\n",
        "def load_dataset(s=\"data\"):\n",
        "    with open('C_train_data.txt') as csv_train_file:\n",
        "           X_train = np.array(list(csv.reader(csv_train_file, delimiter = ','))).astype(\"float\")  \n",
        "    with open('F_train_label.txt') as csv_trainl_file:\n",
        "           labels_train = np.array(list(csv.reader(csv_trainl_file, delimiter = ','))).astype(\"uint\")  \n",
        "    with open('C_test_data.txt') as csv_test_file:\n",
        "           X_test = np.array(list(csv.reader(csv_test_file, delimiter = ','))).astype(\"float\")\n",
        "    with open('F_test_label.txt') as csv_testl_file:\n",
        "           labels_test = np.array(list(csv.reader(csv_testl_file, delimiter = ','))).astype(\"uint\")  \n",
        "    X_train = X_train/X_train.max()\n",
        "    X_test = X_test/X_test.max()\n",
        "    #shuffle the training arrays, not sure if this matters\n",
        "    s = np.arange(0, len(X_train), 1)\n",
        "    np.random.shuffle(s)\n",
        "    X_train = X_train[s]\n",
        "    labels_train = labels_train[s]\n",
        "    return (X_train, labels_train), (X_test, labels_test)\n",
        "  \n",
        "  \n",
        "if(UseMnist):\n",
        "  #load standard MNIST data set\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "else:\n",
        "  (x_train, y_train), (x_test, y_test) = load_dataset()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FByqn1cTzKxS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if(False == UseMnist):\n",
        "  col = np.zeros((60000,3))\n",
        "  x_train = np.hstack((x_train, col))\n",
        "  tcol = np.zeros((10000, 3))\n",
        "  x_test = np.hstack((x_test, tcol))\n",
        "  x_train = x_train.reshape(x_train.shape[0], image_size, image_size)\n",
        "  x_test = x_test.reshape(x_test.shape[0], image_size, image_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBzpxy7iVoQe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Classification in 10 Minutes with MNIST Dataset, adapted from Orhan Gazi Yalzin"
      ]
    },
    {
      "metadata": {
        "id": "bTEIbr4BIiSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "# Only use this if using iPython\n",
        "i = 1000 # You may select anything up to 60,000\n",
        "yo = x_train[i].reshape(image_size, image_size)\n",
        "print(y_train[i])\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(yo, cmap = 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDyGpakufKAU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PIx2 = 2.0*tf.constant(math.pi)\n",
        "PI = tf.constant(math.pi)\n",
        "off = 0.5\n",
        "\n",
        "inhib = 0\n",
        "\n",
        "def ReLU(x):\n",
        "  return tf.maximum(0.0, x)\n",
        "\n",
        "def xsinxRelu(x):\n",
        "  return tf.maximum(0.0,1.0/PIx2*(PIx2*(x+.75) - tf.sin(PIx2*(x+.75))))\n",
        "\n",
        "def expxsinxRelu(x):\n",
        "  s = 1.0\n",
        "  return tf.maximum(0.0,1.0/PIx2*(PIx2*(x+1) - tf.exp(-s*tf.square((x+1)))* tf.sin(PIx2*(x+1))))\n",
        "\n",
        "def xsinxRelu2(x):\n",
        "  return tf.maximum(0.0,1.0/PIx2*(PIx2*(x+.5) - tf.sin(PIx2*(x+.5)))) - 0.5\n",
        "\n",
        "def expxsinxRelu2(x):\n",
        "  s = 1.0\n",
        "  return tf.maximum(0.0,1.0/PIx2*(PIx2*(x+1) - tf.exp(-1*tf.square((x+1)))* tf.sin(PIx2*(x+1)))) - 0.5\n",
        "\n",
        "def xsinxSigmoid(x):\n",
        "  y = tf.minimum(1.0, tf.maximum(0.0,1.0/(PIx2)*((x + PI) - tf.sin((x + PI)))))\n",
        "  return y / tf.reduce_sum(y)\n",
        "\n",
        "def lisht(x):\n",
        "  return x*(tf.exp(x) - tf.exp(-x))/(tf.exp(x) + tf.exp(-x))\n",
        "\n",
        "def swish(x):\n",
        "  return x*tf.exp(x)/(tf.exp(x) + 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O0WVCJiSRZ2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSwx2nXDpDcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1)\n",
        "input_shape = (image_size, image_size, 1)\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])\n",
        "\n",
        "if(UseMnist):\n",
        "  x_train = x_train/255\n",
        "  x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oy7qKLQO8ZbE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#some variables for collecting history of various activation functions\n",
        "H = []\n",
        "TR = []\n",
        "RELU = 0\n",
        "XSINX = 1\n",
        "EXSINX = 2\n",
        "SWISH = 3\n",
        "LISHT = 4\n",
        "\n",
        "funcs = {0:ReLU, 1:xsinxRelu, 2:expxsinxRelu, 3:swish, 4:lisht, 5:xsinxRelu2, 6:expxsinxRelu2}\n",
        "names = {0:\"ReLU\", 1:\"xsinxRelu\", 2:\"expxsinxRelu\", 3:\"swish\", 4:\"lisht\", 5:\"xsinxRelu2\", 6:\"expxsinxRelu2\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hFDAPnRESwuW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(10):\n",
        "  print(i+1)\n",
        "  for k in range(7):\n",
        "    # Importing the required Keras modules containing model and layers\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "    # Creating a Sequential Model and adding the layers\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(image_size, kernel_size=(4,4), input_shape=input_shape, padding = 'same'))\n",
        "    model.add(MaxPooling2D(pool_size=(4,4)))\n",
        "    model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "    #Use 196 for my data  \n",
        "    model.add(Dense(128, activation=funcs[k]))\n",
        "    #model.add(Dense(128, activation=tf.nn.relu))\n",
        "    #model.add(Dense(128, activation = xsinxRelu))\n",
        "    #model.add(Dense(128, activation = expxsinxRelu))\n",
        "    #model.add(Dense(128, activation = swish))\n",
        "    #model.add(Dense(128, activation = lisht))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10,activation=tf.nn.softmax))\n",
        "    #model.add(Dense(10,activation=xsinxSigmoid))\n",
        "  \n",
        "    model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "    print(names[k])\n",
        "    model.fit(x=x_train,y=y_train, epochs=30, verbose = 0)\n",
        "  \n",
        "    #TR.append(model.evaluate(x_test, y_test))\n",
        "    print(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3kn7LQVDT5yl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer='adam', \n",
        "#              loss='sparse_categorical_crossentropy', \n",
        "#              metrics=['accuracy'])\n",
        "#H[0] = model.fit(x=x_train,y=y_train, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JuXOKPzxzJQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4wWFpptH6loX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot metrics\n",
        "#pyplot.plot(H[0].history['loss'], 'r', label='ReLU')\n",
        "#pyplot.plot(H[1].history['loss'], 'b', label='OscReLU')\n",
        "#pyplot.plot(H[2].history['loss'], 'g', label='DOscReLU')\n",
        "#pyplot.plot(H[3].history['loss'], 'c', label='Swish')\n",
        "#pyplot.plot(H[4].history['loss'], 'm', label='Lisht')\n",
        "#pyplot.legend(loc='upper right')\n",
        "#from google.colab import files\n",
        "#plt.savefig(\"MNIST_CNN_LOSS 15_IT OFFSET_1_0.png\")\n",
        "#files.download(\"MNIST_CNN_LOSS 15_IT OFFSET_1_0.png\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73fS6Nx7_PRg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "vSaqYh8Zjs4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot metrics\n",
        "#pyplot.plot(H[0].history['acc'], 'r', label='ReLU')\n",
        "#pyplot.plot(H[1].history['acc'], 'b', label='OscReLU')\n",
        "#pyplot.plot(H[2].history['acc'], 'g', label='DOscReLU')\n",
        "#pyplot.plot(H[3].history['acc'], 'c', label='Swish')\n",
        "#pyplot.plot(H[4].history['acc'], 'm', label='Lisht')\n",
        "#pyplot.legend(loc='lower right')\n",
        "#from google.colab import files\n",
        "#plt.savefig(\"MNIST_CNN_ACC 15_IT OFFSET_1_0.png\")\n",
        "#files.download(\"MNIST_CNN_ACC 15_IT OFFSET_1_0.png\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2isF9dLBkR3R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot metrics\n",
        "#print(TR[0][1], 'ReLU')\n",
        "#print(TR[1][1], 'OscReLU')\n",
        "#print(TR[2][1], 'DOscReLU')\n",
        "#print(TR[3][1], 'Swish')\n",
        "#print(TR[4][1], 'Lisht')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kw1kTd7hVKap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#TR.append(model.evaluate(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJZ58h6Bd3BW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "preds = model.predict(x_test)\n",
        "n_examples = np.random.randint(1, 10000, 10)\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(10):\n",
        "  ax = plt.subplot(2, 10, i + 1)\n",
        "  plt.imshow(x_test[n_examples[i], :, :, 0], cmap='gray')\n",
        "  plt.title(\"Label: {}\\nPredicted:{}\".format(y_test[n_examples[i]], np.argmax(preds[n_examples[i]])))\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5OtxWuPnQtHQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for i in range(preds.shape[0]):\n",
        "  predictions.append(np.argmax(preds[i]))\n",
        "predictions = np.array(predictions)\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (model, metrics.classification_report(y_test, predictions)))\n",
        "print(metrics.confusion_matrix(y_test, predictions))\n",
        "print(\"Accuracy={}\".format(metrics.accuracy_score(y_test, predictions)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYrTLjAkn9mH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "incor = []\n",
        "for i in range(len(y_test)):\n",
        "  label = y_test[i]\n",
        "  pred = np.argmax(preds[i])  \n",
        "  if label != pred:\n",
        "    incor.append(i)\n",
        "incorrect = np.array(incor)\n",
        "\n",
        "print(incorrect.shape[0])\n",
        "n_examples = np.random.randint(1, incorrect.shape[0], 300)\n",
        "\n",
        "plt.figure(figsize=(20, 80))\n",
        "for i in range(incorrect.shape[0]):\n",
        "  ax = plt.subplot(30, 10, i + 1)\n",
        "  plt.imshow(x_test[incorrect[i], :, :, 0], cmap='gray')\n",
        "  plt.title(\"Label: {}\\nPredicted:{}\".format(y_test[incorrect[i]], np.argmax(preds[incorrect[i]])))\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}